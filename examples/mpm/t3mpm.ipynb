{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4efabb5e",
   "metadata": {},
   "source": [
    "# Templatized notebook for running CB-Geo MPM TAPIS job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe5d8a3-32da-4233-b605-9fd51d053ec1",
   "metadata": {},
   "source": [
    "## Install DesignSafe API (dapi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "839fa332-70a6-4818-a190-18c9ca109c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: dapi 1.0.0\n",
      "Uninstalling dapi-1.0.0:\n",
      "  Successfully uninstalled dapi-1.0.0\n",
      "Obtaining file:///Users/krishna/dev/DesignSafe/dapi\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup<2.0.0,>=1.2.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (1.2.2)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (4.23.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=2.1.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (2.1.3)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.2.3 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (2.2.3)\n",
      "Requirement already satisfied: pymysql<2.0.0,>=1.1.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (1.1.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (1.0.1)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.23 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (2.0.36)\n",
      "Requirement already satisfied: tapipy<2.0.0,>=1.6.3 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (1.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (4.67.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from jsonschema>=4.18.0->dapi==1.0.0) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from jsonschema>=4.18.0->dapi==1.0.0) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from jsonschema>=4.18.0->dapi==1.0.0) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from jsonschema>=4.18.0->dapi==1.0.0) (0.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from pandas<3.0.0,>=2.2.3->dapi==1.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from pandas<3.0.0,>=2.2.3->dapi==1.0.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from pandas<3.0.0,>=2.2.3->dapi==1.0.0) (2024.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from sqlalchemy<3.0.0,>=2.0.23->dapi==1.0.0) (4.12.2)\n",
      "Requirement already satisfied: PyJWT>=1.7.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (2.9.0)\n",
      "Requirement already satisfied: atomicwrites<2.0.0,>=1.4.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (1.4.1)\n",
      "Requirement already satisfied: certifi>=2020.11.8 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (2024.8.30)\n",
      "Requirement already satisfied: cloudpickle>=1.6.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (3.1.0)\n",
      "Requirement already satisfied: cryptography>=3.3.2 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (43.0.3)\n",
      "Requirement already satisfied: openapi_core==0.16.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (0.16.0)\n",
      "Requirement already satisfied: openapi_spec_validator<0.6.0,>=0.5.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (0.5.4)\n",
      "Requirement already satisfied: pyyaml>=5.4 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (6.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.20.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (75.4.0)\n",
      "Requirement already satisfied: six<2.0,>=1.10 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.5 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (1.26.20)\n",
      "Requirement already satisfied: isodate in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (0.7.2)\n",
      "Requirement already satisfied: jsonschema-spec<0.2.0,>=0.1.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (0.1.3)\n",
      "Requirement already satisfied: more-itertools in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (10.5.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.4.0,>=0.3.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (0.3.4)\n",
      "Requirement already satisfied: parse in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (1.20.2)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (0.4.3)\n",
      "Requirement already satisfied: werkzeug in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (3.1.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from cryptography>=3.3.2->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (1.17.1)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_spec_validator<0.6.0,>=0.5.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (1.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from requests<3.0.0,>=2.20.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from requests<3.0.0,>=2.20.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (3.10)\n",
      "Requirement already satisfied: pycparser in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from cffi>=1.12->cryptography>=3.3.2->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from werkzeug->openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (3.0.2)\n",
      "Building wheels for collected packages: dapi\n",
      "  Building editable for dapi (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dapi: filename=dapi-1.0.0-py3-none-any.whl size=3825 sha256=f9fd4761dd2e940e7cd0f96795280478e27aacfbc14275ffb57c0ee44f9b129c\n",
      "  Stored in directory: /private/var/folders/w8/xz590jyd7r36zmxcspgzj3z40000gn/T/pip-ephem-wheel-cache-q5wx61zs/wheels/98/df/91/ed70fe2dca11c3c6e5b6e8e6eef18c373a119d095037f892a3\n",
      "Successfully built dapi\n",
      "Installing collected packages: dapi\n",
      "Successfully installed dapi-1.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall dapi --yes\n",
    "!pip install -e ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fca324-ee48-41c8-84a1-78ad7b03aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dapi import (\n",
    "    DSClient,\n",
    "    AppDiscoveryError,\n",
    "    FileOperationError,\n",
    "    JobSubmissionError,\n",
    "    JobMonitorError,\n",
    ")\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dataclasses import asdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58b62f77-23b6-4355-91f1-b680ae6d6cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ds = DSClient()\n",
    "except Exception as e:\n",
    "    print(f\"Authentication failed: {e}\")\n",
    "    raise SystemExit(\"Stopping notebook due to authentication failure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feee3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path: str = \"/MyData/mpm-benchmarks/2d/uniaxial_stress/\"\n",
    "input_filename: str = \"mpm.json\"\n",
    "max_job_minutes: int = 10\n",
    "# queue: str = \"skx\" # Example override - only if needed and valid\n",
    "tacc_allocation: str = \"BCS20003\"\n",
    "app_id_to_use = \"mpm\"  # Or \"mpm-s3\" - use the correct ID verified on DesignSafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0ee687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated '/MyData/mpm-benchmarks/2d/uniaxial_stress/' to 'tapis://designsafe.storage.default/kks32/mpm-benchmarks/2d/uniaxial_stress/' using t.username\n",
      "Input Directory Tapis URI: tapis://designsafe.storage.default/kks32/mpm-benchmarks/2d/uniaxial_stress/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    input_uri = ds.files.translate_path_to_uri(ds_path)\n",
    "    print(f\"Input Directory Tapis URI: {input_uri}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error translating path '{ds_path}': {e}\")\n",
    "    raise SystemExit(\"Stopping notebook due to path translation error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6257d31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating job request dictionary using app defaults and overrides...\n",
      "Generating job request for app 'mpm'...\n",
      "Using App Details: mpm v1.1.0\n",
      "Placing script 'mpm.json' in appArgs: 'Input Script'\n",
      "Adding allocation: BCS20003\n",
      "Job request dictionary generated successfully.\n",
      "\n",
      "--- Generated Job Request Dictionary ---\n",
      "{\n",
      "  \"name\": \"mpm-20250427_095544\",\n",
      "  \"appId\": \"mpm\",\n",
      "  \"appVersion\": \"1.1.0\",\n",
      "  \"description\": \"Material Point Method (MPM) is a particle based method that represents the material as a collection of material points, and their deformations are determined by Newton\\u2019s laws of motion.\",\n",
      "  \"execSystemId\": \"frontera\",\n",
      "  \"archiveSystemId\": \"frontera\",\n",
      "  \"archiveOnAppError\": true,\n",
      "  \"execSystemLogicalQueue\": \"normal\",\n",
      "  \"nodeCount\": 3,\n",
      "  \"coresPerNode\": 56,\n",
      "  \"maxMinutes\": 10,\n",
      "  \"memoryMB\": 192000,\n",
      "  \"isMpi\": false,\n",
      "  \"tags\": [],\n",
      "  \"fileInputs\": [\n",
      "    {\n",
      "      \"name\": \"Input Directory\",\n",
      "      \"sourceUrl\": \"tapis://designsafe.storage.default/kks32/mpm-benchmarks/2d/uniaxial_stress/\",\n",
      "      \"autoMountLocal\": true,\n",
      "      \"targetPath\": \"inputDirectory\"\n",
      "    }\n",
      "  ],\n",
      "  \"parameterSet\": {\n",
      "    \"appArgs\": [\n",
      "      {\n",
      "        \"name\": \"Input Script\",\n",
      "        \"arg\": \"mpm.json\"\n",
      "      }\n",
      "    ],\n",
      "    \"schedulerOptions\": [\n",
      "      {\n",
      "        \"name\": \"TACC Allocation\",\n",
      "        \"arg\": \"-A BCS20003\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"\\nGenerating job request dictionary using app defaults and overrides...\")\n",
    "    # Call the generate_request method\n",
    "    job_req_dict = ds.jobs.generate_request(\n",
    "        app_id=app_id_to_use,\n",
    "        input_dir_uri=input_uri,\n",
    "        script_filename=input_filename,\n",
    "        # --- Provide overrides here ---\n",
    "        max_minutes=max_job_minutes,\n",
    "        allocation=tacc_allocation,\n",
    "        # queue=queue, # Only include if overriding\n",
    "        # job_name=\"my_custom_mpm_job\", # Optional name override\n",
    "        # node_count=1, # Optional resource override\n",
    "        # cores_per_node=1, # Optional resource override\n",
    "    )\n",
    "    print(\"\\n--- Generated Job Request Dictionary ---\")\n",
    "    print(json.dumps(job_req_dict, indent=2, default=str))\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "except (\n",
    "    AppDiscoveryError,\n",
    "    ValueError,\n",
    "    JobSubmissionError,\n",
    ") as e:  # Catch errors during generation\n",
    "    print(f\"Error generating job request: {e}\")\n",
    "    raise SystemExit(\"Stopping notebook due to job request generation error.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during job request generation: {e}\")\n",
    "    raise SystemExit(\"Stopping notebook due to unexpected generation error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, the user can inspect and modify job_req_dict if needed.\n",
    "# For example:\n",
    "# print(\"Modifying job request dictionary...\")\n",
    "# job_req_dict['description'] = \"My modified description\"\n",
    "# job_req_dict['parameterSet']['envVariables'].append({'key': 'MY_EXTRA_VAR', 'value': 'extra_value'})\n",
    "# print(\"\\n--- Modified Job Request Dictionary ---\")\n",
    "# print(json.dumps(job_req_dict, indent=2, default=str))\n",
    "# print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e04a5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitting the job request dictionary...\n",
      "\n",
      "--- Submitting Tapis Job Request ---\n",
      "{\n",
      "  \"name\": \"mpm-20250427_095544\",\n",
      "  \"appId\": \"mpm\",\n",
      "  \"appVersion\": \"1.1.0\",\n",
      "  \"description\": \"Material Point Method (MPM) is a particle based method that represents the material as a collection of material points, and their deformations are determined by Newton\\u2019s laws of motion.\",\n",
      "  \"execSystemId\": \"frontera\",\n",
      "  \"archiveSystemId\": \"frontera\",\n",
      "  \"archiveOnAppError\": true,\n",
      "  \"execSystemLogicalQueue\": \"normal\",\n",
      "  \"nodeCount\": 3,\n",
      "  \"coresPerNode\": 56,\n",
      "  \"maxMinutes\": 10,\n",
      "  \"memoryMB\": 192000,\n",
      "  \"isMpi\": false,\n",
      "  \"tags\": [],\n",
      "  \"fileInputs\": [\n",
      "    {\n",
      "      \"name\": \"Input Directory\",\n",
      "      \"sourceUrl\": \"tapis://designsafe.storage.default/kks32/mpm-benchmarks/2d/uniaxial_stress/\",\n",
      "      \"autoMountLocal\": true,\n",
      "      \"targetPath\": \"inputDirectory\"\n",
      "    }\n",
      "  ],\n",
      "  \"parameterSet\": {\n",
      "    \"appArgs\": [\n",
      "      {\n",
      "        \"name\": \"Input Script\",\n",
      "        \"arg\": \"mpm.json\"\n",
      "      }\n",
      "    ],\n",
      "    \"schedulerOptions\": [\n",
      "      {\n",
      "        \"name\": \"TACC Allocation\",\n",
      "        \"arg\": \"-A BCS20003\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "------------------------------------\n",
      "Job submitted successfully. UUID: b196bf63-795e-4533-9544-b9ef16b1a04c-007\n",
      "Job Submitted Successfully!\n",
      "Job UUID: b196bf63-795e-4533-9544-b9ef16b1a04c-007\n"
     ]
    }
   ],
   "source": [
    "if \"job_req_dict\" not in locals():\n",
    "    print(\"Error: job_req_dict not found. Please run the previous cell.\")\n",
    "    raise SystemExit(\"Stopping notebook.\")\n",
    "\n",
    "try:\n",
    "    print(\"\\nSubmitting the job request dictionary...\")\n",
    "    # Pass the potentially modified dictionary to submit_request\n",
    "    submitted_job = ds.jobs.submit_request(job_req_dict)\n",
    "    print(f\"Job Submitted Successfully!\")\n",
    "    print(f\"Job UUID: {submitted_job.uuid}\")\n",
    "\n",
    "except JobSubmissionError as e:\n",
    "    print(f\"Job submission failed: {e}\")\n",
    "    # Print the dictionary that was attempted\n",
    "    print(\"\\n--- Failed Job Request ---\")\n",
    "    print(json.dumps(job_req_dict, indent=2, default=str))\n",
    "    print(\"--------------------------\")\n",
    "    raise SystemExit(\"Stopping notebook due to job submission error.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during job submission: {e}\")\n",
    "    raise SystemExit(\"Stopping notebook due to unexpected submission error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd46a8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Monitoring job b196bf63-795e-4533-9544-b9ef16b1a04c-007...\n",
      "Monitoring job b196bf63-795e-4533-9544-b9ef16b1a04c-007 (Initial Status: STAGING_JOB, Timeout: 10 mins, Interval: 30s)\n",
      "\tJob b196bf63-795e-4533-9544-b9ef16b1a04c-007 Status: QUEUED (2025-04-27T09:59:31.487189)\n",
      "\tJob b196bf63-795e-4533-9544-b9ef16b1a04c-007 Status: RUNNING (2025-04-27T10:00:01.917496)\n",
      "\tJob b196bf63-795e-4533-9544-b9ef16b1a04c-007 Status: ARCHIVING (2025-04-27T10:03:05.393456)\n",
      "\n",
      "Error during monitoring for job b196bf63-795e-4533-9544-b9ef16b1a04c-007: Monitoring timeout after 10 minutes for job b196bf63-795e-4533-9544-b9ef16b1a04c-007. Last status: ARCHIVING\n",
      "\n",
      "Job monitoring failed or timed out: Error monitoring job b196bf63-795e-4533-9544-b9ef16b1a04c-007: Monitoring timeout after 10 minutes for job b196bf63-795e-4533-9544-b9ef16b1a04c-007. Last status: ARCHIVING\n",
      "Last known status: ARCHIVING\n"
     ]
    }
   ],
   "source": [
    "if \"submitted_job\" not in locals():\n",
    "    print(\"Error: submitted_job not found.\")\n",
    "    raise SystemExit(\"Stopping notebook.\")\n",
    "try:\n",
    "    print(f\"\\nMonitoring job {submitted_job.uuid}...\")\n",
    "    final_status = submitted_job.monitor(interval=30)\n",
    "    print(f\"\\nJob {submitted_job.uuid} finished monitoring.\")\n",
    "    print(f\"Final Status: {final_status}\")\n",
    "except JobMonitorError as e:\n",
    "    print(f\"\\nJob monitoring failed or timed out: {e}\")\n",
    "    final_status = submitted_job.status\n",
    "    print(f\"Last known status: {final_status}\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nMonitoring stopped by user.\")\n",
    "    final_status = submitted_job.status\n",
    "    print(f\"Last known status: {final_status}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred during monitoring: {e}\")\n",
    "    try:\n",
    "        final_status = submitted_job.status\n",
    "        print(f\"Last known status: {final_status}\")\n",
    "    except:\n",
    "        final_status = \"UNKNOWN\"\n",
    "        print(\"Could not retrieve last known status.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a6daeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipping runtime summary because job b196bf63-795e-4533-9544-b9ef16b1a04c-007 did not finish normally (Status: ARCHIVING).\n"
     ]
    }
   ],
   "source": [
    "if \"final_status\" in locals() and final_status in [\"FINISHED\", \"FAILED\"]:\n",
    "    print(f\"\\nAttempting to display runtime summary for job {submitted_job.uuid}...\")\n",
    "    try:\n",
    "        submitted_job.print_runtime_summary(verbose=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not display runtime summary: {e}\")\n",
    "elif \"submitted_job\" in locals():\n",
    "    print(\n",
    "        f\"\\nSkipping runtime summary because job {submitted_job.uuid} did not finish normally (Status: {final_status}).\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"\\nSkipping runtime summary as job submission or monitoring did not complete.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fe8ac5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipping archive listing as job did not complete or submission/monitoring failed.\n"
     ]
    }
   ],
   "source": [
    "if (\n",
    "    \"submitted_job\" in locals()\n",
    "    and \"final_status\" in locals()\n",
    "    and final_status in [\"FINISHED\", \"FAILED\", \"CANCELLED\", \"STOPPED\"]\n",
    "):\n",
    "    print(f\"\\nAttempting to access archive information for job {submitted_job.uuid}...\")\n",
    "    try:\n",
    "        archive_uri = submitted_job.archive_uri\n",
    "        if archive_uri:\n",
    "            print(f\"Job Archive Tapis URI: {archive_uri}\")\n",
    "            print(\"\\nListing archive contents (root):\")\n",
    "            outputs = ds.files.list(archive_uri)\n",
    "            if outputs:\n",
    "                for item in outputs:\n",
    "                    print(\n",
    "                        f\"- {item.name} (Type: {item.type}, Size: {item.size} bytes, Modified: {item.lastModified})\"\n",
    "                    )\n",
    "            else:\n",
    "                print(\"No files found in the archive root directory.\")\n",
    "        else:\n",
    "            print(\"Archive URI not available for this job.\")\n",
    "    except FileOperationError as e:\n",
    "        print(f\"Could not list archive files: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while accessing archive information: {e}\")\n",
    "else:\n",
    "    print(\n",
    "        \"\\nSkipping archive listing as job did not complete or submission/monitoring failed.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335379df-6e64-475e-8c14-5c8c748e818e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90 total apps.\n"
     ]
    }
   ],
   "source": [
    "# Find all apps (less verbose)\n",
    "all_apps = ds.apps.find(\"\", verbose=False)\n",
    "print(f\"Found {len(all_apps)} total apps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5574dcd-2c32-4822-be12-fe558747ebde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 2 matching apps:\n",
      "- mpm (Version: 1.1.0, Owner: wma_prtl)\n",
      "- mpm-s3 (Version: 1.0, Owner: wma_prtl)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find MPM apps specifically\n",
    "mpm_apps = ds.apps.find(\"mpm\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37074448-fe54-4aab-b458-cfe9dc1a5101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "App Details:\n",
      "  ID: opensees-express\n",
      "  Version: latest\n",
      "  Owner: wma_prtl\n",
      "  Execution System: wma-exec-01\n",
      "  Description: OpenSees-EXPRESS provides users with a sequential OpenSees interpreter. It is ideal to run small sequential scripts on DesignSafe resources freeing up your own machine.\n",
      "App Description: \n",
      "containerImage: tapis://cloud.data/corral/tacc/aci/CEP/applications/v3/opensees/latest/OpenSees-EXPRESS/opensees_express.zip\n",
      "created: 2025-02-20T18:41:03.661272Z\n",
      "deleted: False\n",
      "description: OpenSees-EXPRESS provides users with a sequential OpenSees interpreter. It is ideal to run small sequential scripts on DesignSafe resources freeing up your own machine.\n",
      "enabled: True\n",
      "id: opensees-express\n",
      "isPublic: True\n",
      "jobAttributes: \n",
      "archiveOnAppError: True\n",
      "archiveSystemDir: /tmp/${JobOwner}/tapis-jobs-archive/${JobCreateDate}/${JobName}-${JobUUID}\n",
      "archiveSystemId: cloud.data\n",
      "cmdPrefix: None\n",
      "coresPerNode: 1\n",
      "description: None\n",
      "dtnSystemInputDir: !tapis_not_set\n",
      "dtnSystemOutputDir: !tapis_not_set\n",
      "dynamicExecSystem: False\n",
      "execSystemConstraints: None\n",
      "execSystemExecDir: ${JobWorkingDir}\n",
      "execSystemId: wma-exec-01\n",
      "execSystemInputDir: ${JobWorkingDir}\n",
      "execSystemLogicalQueue: None\n",
      "execSystemOutputDir: ${JobWorkingDir}\n",
      "fileInputArrays: []\n",
      "fileInputs: [\n",
      "autoMountLocal: True\n",
      "description: Input directory that includes the tcl script as well as any other required files. Example input is in tapis://designsafe.storage.community/app_examples/opensees/OpenSeesEXPRESS\n",
      "envKey: inputDirectory\n",
      "inputMode: REQUIRED\n",
      "name: Input Directory\n",
      "notes: \n",
      "selectionMode: directory\n",
      "sourceUrl: None\n",
      "targetPath: *]\n",
      "isMpi: False\n",
      "maxMinutes: 1440\n",
      "memoryMB: 100\n",
      "mpiCmd: None\n",
      "nodeCount: 1\n",
      "parameterSet: \n",
      "appArgs: []\n",
      "archiveFilter: \n",
      "excludes: ['opensees-express.zip', 'tapisjob.env']\n",
      "includeLaunchFiles: True\n",
      "includes: []\n",
      "containerArgs: []\n",
      "envVariables: [\n",
      "description: Choose the OpenSees binary to use.\n",
      "inputMode: REQUIRED\n",
      "key: mainProgram\n",
      "notes: \n",
      "enum_values: [\n",
      "OpenSees: OpenSees, \n",
      "OpenSeesSP: OpenSeesSP, \n",
      "OpenSeesMP: OpenSeesMP]\n",
      "label: Main Program\n",
      "value: OpenSees, \n",
      "description: The filename of the OpenSees TCL script to execute, e.g. \"freeFieldEffective.tcl\".\n",
      "inputMode: REQUIRED\n",
      "key: tclScript\n",
      "notes: \n",
      "inputType: fileInput\n",
      "label: Main Script\n",
      "value: ]\n",
      "logConfig: \n",
      "stderrFilename: \n",
      "stdoutFilename: \n",
      "schedulerOptions: []\n",
      "subscriptions: []\n",
      "tags: []\n",
      "jobType: FORK\n",
      "locked: False\n",
      "maxJobs: 2147483647\n",
      "maxJobsPerUser: 2147483647\n",
      "notes: \n",
      "category: Simulation\n",
      "helpUrl: https://www.designsafe-ci.org/user-guide/tools/simulation/#opensees-user-guide\n",
      "hideNodeCountAndCoresPerNode: True\n",
      "icon: OpenSees\n",
      "isInteractive: False\n",
      "label: OpenSees-EXPRESS (VM)\n",
      "owner: wma_prtl\n",
      "runtime: ZIP\n",
      "runtimeOptions: None\n",
      "runtimeVersion: None\n",
      "sharedAppCtx: wma_prtl\n",
      "sharedWithUsers: []\n",
      "strictFileInputs: True\n",
      "tags: ['portalName: DesignSafe', 'portalName: CEP']\n",
      "tenant: designsafe\n",
      "updated: 2025-02-26T21:17:36.417952Z\n",
      "uuid: 30cb1fa1-e7c7-44a8-a0e8-d2f64043fc65\n",
      "version: latest\n",
      "versionEnabled: True\n"
     ]
    }
   ],
   "source": [
    "# Get details for the specific MPM app we want to use\n",
    "app_id_to_use = \"opensees-express\"\n",
    "app_details = ds.apps.get_details(app_id_to_use, verbose=True)\n",
    "\n",
    "if not app_details:\n",
    "    raise SystemExit(\n",
    "        f\"Could not find details for app '{app_id_to_use}'. Please check the app ID.\"\n",
    "    )\n",
    "# Print the app details\n",
    "\n",
    "print(f\"App Description: {app_details}\")"
   ]
  }
 ],
 "metadata": {
  "IMAGE_NAME": "taccsciapps/ds-nb-img:base-0.2.1",
  "UUID": "ad99fe82-d690-11ec-8bc3-165d4cd45074",
  "kernelspec": {
   "display_name": "dapi-ptztLUqK-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
