{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4efabb5e",
   "metadata": {},
   "source": [
    "# Templatized notebook for running CB-Geo MPM TAPIS job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe5d8a3-32da-4233-b605-9fd51d053ec1",
   "metadata": {},
   "source": [
    "## Install DesignSafe API (dapi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839fa332-70a6-4818-a190-18c9ca109c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: dapi 1.0.0\n",
      "Uninstalling dapi-1.0.0:\n",
      "  Successfully uninstalled dapi-1.0.0\n",
      "Obtaining file:///Users/krishna/dev/DesignSafe/dapi\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup<2.0.0,>=1.2.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (1.2.2)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (4.23.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=2.1.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (2.1.3)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.2.3 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (2.2.3)\n",
      "Requirement already satisfied: pymysql<2.0.0,>=1.1.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (1.1.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (1.0.1)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.23 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (2.0.36)\n",
      "Requirement already satisfied: tapipy<2.0.0,>=1.6.3 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (1.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from dapi==1.0.0) (4.67.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from jsonschema>=4.18.0->dapi==1.0.0) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from jsonschema>=4.18.0->dapi==1.0.0) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from jsonschema>=4.18.0->dapi==1.0.0) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from jsonschema>=4.18.0->dapi==1.0.0) (0.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from pandas<3.0.0,>=2.2.3->dapi==1.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from pandas<3.0.0,>=2.2.3->dapi==1.0.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from pandas<3.0.0,>=2.2.3->dapi==1.0.0) (2024.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from sqlalchemy<3.0.0,>=2.0.23->dapi==1.0.0) (4.12.2)\n",
      "Requirement already satisfied: PyJWT>=1.7.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (2.9.0)\n",
      "Requirement already satisfied: atomicwrites<2.0.0,>=1.4.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (1.4.1)\n",
      "Requirement already satisfied: certifi>=2020.11.8 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (2024.8.30)\n",
      "Requirement already satisfied: cloudpickle>=1.6.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (3.1.0)\n",
      "Requirement already satisfied: cryptography>=3.3.2 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (43.0.3)\n",
      "Requirement already satisfied: openapi_core==0.16.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (0.16.0)\n",
      "Requirement already satisfied: openapi_spec_validator<0.6.0,>=0.5.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (0.5.4)\n",
      "Requirement already satisfied: pyyaml>=5.4 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (6.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.20.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (75.4.0)\n",
      "Requirement already satisfied: six<2.0,>=1.10 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.5 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (1.26.20)\n",
      "Requirement already satisfied: isodate in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (0.7.2)\n",
      "Requirement already satisfied: jsonschema-spec<0.2.0,>=0.1.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (0.1.3)\n",
      "Requirement already satisfied: more-itertools in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (10.5.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.4.0,>=0.3.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (0.3.4)\n",
      "Requirement already satisfied: parse in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (1.20.2)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.0 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (0.4.3)\n",
      "Requirement already satisfied: werkzeug in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (3.1.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from cryptography>=3.3.2->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (1.17.1)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from openapi_spec_validator<0.6.0,>=0.5.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (1.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from requests<3.0.0,>=2.20.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from requests<3.0.0,>=2.20.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (3.10)\n",
      "Requirement already satisfied: pycparser in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from cffi>=1.12->cryptography>=3.3.2->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages (from werkzeug->openapi_core==0.16.0->tapipy<2.0.0,>=1.6.3->dapi==1.0.0) (3.0.2)\n",
      "Building wheels for collected packages: dapi\n",
      "  Building editable for dapi (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dapi: filename=dapi-1.0.0-py3-none-any.whl size=3826 sha256=25a5c9308663e0078f3b0943613ad978d718bb5f64c36fd23162943a7d68b56f\n",
      "  Stored in directory: /private/var/folders/w8/xz590jyd7r36zmxcspgzj3z40000gn/T/pip-ephem-wheel-cache-sjzyd4es/wheels/98/df/91/ed70fe2dca11c3c6e5b6e8e6eef18c373a119d095037f892a3\n",
      "Successfully built dapi\n",
      "Installing collected packages: dapi\n",
      "Successfully installed dapi-1.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Dapi installation\n",
    "!pip uninstall dapi --yes\n",
    "\n",
    "!pip install dapi --user --quiet\n",
    "\n",
    "# Install the latest development version of dapi from GitHub\n",
    "# !pip install git+https://github.com/DesignSafe-CI/dapi.git@dev --user --quiet\n",
    "\n",
    "# Install editable local version of dapi\n",
    "# !pip install -e ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fca324-ee48-41c8-84a1-78ad7b03aae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Import only DSClient and exceptions needed at top level\n",
    "from dapi import (\n",
    "    DSClient,\n",
    "    SubmittedJob,\n",
    "    interpret_job_status,  # Import new function\n",
    "    AppDiscoveryError,\n",
    "    FileOperationError,\n",
    "    JobSubmissionError,\n",
    "    SystemInfoError,\n",
    "    JobMonitorError,\n",
    "    # Optionally import status constants if you want to check against them explicitly\n",
    "    STATUS_TIMEOUT,\n",
    "    STATUS_UNKNOWN,\n",
    "    TAPIS_TERMINAL_STATES,\n",
    ")\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dataclasses import asdict\n",
    "import pandas as pd\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58b62f77-23b6-4355-91f1-b680ae6d6cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DSClient...\n",
      "Authentication successful.\n",
      "DatabaseAccessor initialized. Connections will be created on first access.\n",
      "DSClient initialized.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Initializing DSClient...\")\n",
    "    ds = DSClient()\n",
    "    print(\"DSClient initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"Initialization failed: {e}\")\n",
    "    raise SystemExit(\"Stopping notebook due to client initialization failure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feee3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path: str = \"/MyData/mpm-benchmarks/2d/uniaxial_stress/\"\n",
    "input_filename: str = \"mpm.json\"\n",
    "max_job_minutes: int = 10\n",
    "# queue: str = \"skx\" # Example override - only if needed and valid\n",
    "# tacc_allocation: str = \"BCS20003\"\n",
    "tacc_allocation: str = \"ASC25049\"\n",
    "app_id_to_use = \"mpm-s3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0ee687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated '/MyData/mpm-benchmarks/2d/uniaxial_stress/' to 'tapis://designsafe.storage.default/kks32/mpm-benchmarks/2d/uniaxial_stress/' using t.username\n",
      "Input Directory Tapis URI: tapis://designsafe.storage.default/kks32/mpm-benchmarks/2d/uniaxial_stress/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    input_uri = ds.files.translate_path_to_uri(ds_path)\n",
    "    print(f\"Input Directory Tapis URI: {input_uri}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error translating path '{ds_path}': {e}\")\n",
    "    raise SystemExit(\"Stopping notebook due to path translation error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6257d31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating job request dictionary...\n",
      "Generating job request for app 'mpm-s3'...\n",
      "Using App Details: mpm-s3 v1.0\n",
      "Placing script 'mpm.json' in appArgs: 'Input Script'\n",
      "Adding allocation: ASC25049\n",
      "Job request dictionary generated successfully.\n",
      "\n",
      "--- Generated Job Request Dictionary ---\n",
      "{\n",
      "  \"name\": \"mpm-s3-20250604_081741\",\n",
      "  \"appId\": \"mpm-s3\",\n",
      "  \"appVersion\": \"1.0\",\n",
      "  \"description\": \"Material Point Method (MPM) is a particle based method that represents the material as a collection of material points, and their deformations are determined by Newton\\u2019s laws of motion.\",\n",
      "  \"execSystemId\": \"stampede3\",\n",
      "  \"archiveSystemId\": \"stampede3\",\n",
      "  \"archiveOnAppError\": true,\n",
      "  \"execSystemLogicalQueue\": \"skx-dev\",\n",
      "  \"nodeCount\": 1,\n",
      "  \"coresPerNode\": 48,\n",
      "  \"maxMinutes\": 10,\n",
      "  \"memoryMB\": 192000,\n",
      "  \"isMpi\": false,\n",
      "  \"tags\": [],\n",
      "  \"fileInputs\": [\n",
      "    {\n",
      "      \"name\": \"Input Directory\",\n",
      "      \"sourceUrl\": \"tapis://designsafe.storage.default/kks32/mpm-benchmarks/2d/uniaxial_stress/\",\n",
      "      \"autoMountLocal\": true,\n",
      "      \"targetPath\": \"inputDirectory\"\n",
      "    }\n",
      "  ],\n",
      "  \"parameterSet\": {\n",
      "    \"appArgs\": [\n",
      "      {\n",
      "        \"name\": \"Input Script\",\n",
      "        \"arg\": \"mpm.json\"\n",
      "      }\n",
      "    ],\n",
      "    \"schedulerOptions\": [\n",
      "      {\n",
      "        \"name\": \"TACC Allocation\",\n",
      "        \"arg\": \"-A ASC25049\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"\\nGenerating job request dictionary...\")\n",
    "    job_dict = ds.jobs.generate_request(\n",
    "        app_id=app_id_to_use,\n",
    "        input_dir_uri=input_uri,\n",
    "        script_filename=input_filename,\n",
    "        max_minutes=max_job_minutes,\n",
    "        allocation=tacc_allocation,\n",
    "    )\n",
    "    print(\"\\n--- Generated Job Request Dictionary ---\")\n",
    "    print(json.dumps(job_dict, indent=2, default=str))\n",
    "    print(\"---------------------------------------\")\n",
    "except (AppDiscoveryError, ValueError, JobSubmissionError) as e:\n",
    "    print(f\"Error generating job request: {e}\")\n",
    "    raise SystemExit(\"Stopping notebook due to job request generation error.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during job request generation: {e}\")\n",
    "    raise SystemExit(\"Stopping notebook due to unexpected generation error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a17eee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modifying job request dictionary...\n",
      "{\n",
      "  \"name\": \"mpm-s3-20250604_081741\",\n",
      "  \"appId\": \"mpm-s3\",\n",
      "  \"appVersion\": \"1.0\",\n",
      "  \"description\": \"Material Point Method (MPM) is a particle based method that represents the material as a collection of material points, and their deformations are determined by Newton\\u2019s laws of motion.\",\n",
      "  \"execSystemId\": \"stampede3\",\n",
      "  \"archiveSystemId\": \"stampede3\",\n",
      "  \"archiveOnAppError\": true,\n",
      "  \"execSystemLogicalQueue\": \"skx-dev\",\n",
      "  \"nodeCount\": 1,\n",
      "  \"coresPerNode\": 1,\n",
      "  \"maxMinutes\": 10,\n",
      "  \"memoryMB\": 192000,\n",
      "  \"isMpi\": false,\n",
      "  \"tags\": [],\n",
      "  \"fileInputs\": [\n",
      "    {\n",
      "      \"name\": \"Input Directory\",\n",
      "      \"sourceUrl\": \"tapis://designsafe.storage.default/kks32/mpm-benchmarks/2d/uniaxial_stress/\",\n",
      "      \"autoMountLocal\": true,\n",
      "      \"targetPath\": \"inputDirectory\"\n",
      "    }\n",
      "  ],\n",
      "  \"parameterSet\": {\n",
      "    \"appArgs\": [\n",
      "      {\n",
      "        \"name\": \"Input Script\",\n",
      "        \"arg\": \"mpm.json\"\n",
      "      }\n",
      "    ],\n",
      "    \"schedulerOptions\": [\n",
      "      {\n",
      "        \"name\": \"TACC Allocation\",\n",
      "        \"arg\": \"-A ASC25049\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# At this point, the user can inspect and modify job_dict if needed.\n",
    "# For example:\n",
    "print(\"Modifying job request dictionary...\")\n",
    "job_dict[\"nodeCount\"] = 1\n",
    "job_dict[\"coresPerNode\"] = 1\n",
    "# job_dict[\"execSystemLogicalQueue\"] = \"development\"\n",
    "\n",
    "print(json.dumps(job_dict, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e04a5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitting the job request dictionary...\n",
      "\n",
      "--- Submitting Tapis Job Request ---\n",
      "{\n",
      "  \"name\": \"mpm-s3-20250604_081741\",\n",
      "  \"appId\": \"mpm-s3\",\n",
      "  \"appVersion\": \"1.0\",\n",
      "  \"description\": \"Material Point Method (MPM) is a particle based method that represents the material as a collection of material points, and their deformations are determined by Newton\\u2019s laws of motion.\",\n",
      "  \"execSystemId\": \"stampede3\",\n",
      "  \"archiveSystemId\": \"stampede3\",\n",
      "  \"archiveOnAppError\": true,\n",
      "  \"execSystemLogicalQueue\": \"skx-dev\",\n",
      "  \"nodeCount\": 1,\n",
      "  \"coresPerNode\": 1,\n",
      "  \"maxMinutes\": 10,\n",
      "  \"memoryMB\": 192000,\n",
      "  \"isMpi\": false,\n",
      "  \"tags\": [],\n",
      "  \"fileInputs\": [\n",
      "    {\n",
      "      \"name\": \"Input Directory\",\n",
      "      \"sourceUrl\": \"tapis://designsafe.storage.default/kks32/mpm-benchmarks/2d/uniaxial_stress/\",\n",
      "      \"autoMountLocal\": true,\n",
      "      \"targetPath\": \"inputDirectory\"\n",
      "    }\n",
      "  ],\n",
      "  \"parameterSet\": {\n",
      "    \"appArgs\": [\n",
      "      {\n",
      "        \"name\": \"Input Script\",\n",
      "        \"arg\": \"mpm.json\"\n",
      "      }\n",
      "    ],\n",
      "    \"schedulerOptions\": [\n",
      "      {\n",
      "        \"name\": \"TACC Allocation\",\n",
      "        \"arg\": \"-A ASC25049\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "------------------------------------\n",
      "Job submitted successfully. UUID: 52f48eaf-b7d6-4964-a97b-a4b32a6aaeb3-007\n",
      "Job Submitted Successfully!\n",
      "Job UUID: 52f48eaf-b7d6-4964-a97b-a4b32a6aaeb3-007\n"
     ]
    }
   ],
   "source": [
    "if \"job_dict\" not in locals():\n",
    "    print(\"Error: job_dict not found.\")\n",
    "    raise SystemExit(\"Stopping notebook.\")\n",
    "try:\n",
    "    print(\"\\nSubmitting the job request dictionary...\")\n",
    "    submitted_job = ds.jobs.submit_request(job_dict)\n",
    "    print(f\"Job Submitted Successfully!\")\n",
    "    print(f\"Job UUID: {submitted_job.uuid}\")\n",
    "except JobSubmissionError as e:\n",
    "    print(f\"Job submission failed: {e}\")\n",
    "    print(\"\\n--- Failed Job Request ---\")\n",
    "    print(json.dumps(job_dict, indent=2, default=str))\n",
    "    print(\"--------------------------\")\n",
    "    raise SystemExit(\"Stopping notebook due to job submission error.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during job submission: {e}\")\n",
    "    raise SystemExit(\"Stopping notebook due to unexpected submission error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd6089f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Monitoring Job: 52f48eaf-b7d6-4964-a97b-a4b32a6aaeb3-007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitoring job:   0%|                                                   | 0/40 [00:00<?, ? checks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStatus: RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitoring job (Status: ARCHIVING):   8%|█▋                     | 3/40 [00:30<06:42, 10.88s/ checks]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStatus: ARCHIVING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitoring job (Status: ARCHIVING): 100%|██████████████████████| 40/40 [01:01<00:00,  1.54s/ checks]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStatus: FINISHED\n",
      "\n",
      "Job 52f48eaf-b7d6-4964-a97b-a4b32a6aaeb3-007 monitoring finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if \"submitted_job\" not in locals():\n",
    "    print(\"Error: submitted_job not found.\")\n",
    "    raise SystemExit(\"Stopping notebook.\")\n",
    "\n",
    "# Call monitor - exceptions are handled inside now, returns status string\n",
    "final_status = submitted_job.monitor(interval=15)  # Use 15s interval\n",
    "\n",
    "print(f\"\\nJob {submitted_job.uuid} monitoring finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a6daeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Job Outcome ---\n",
      "Job 52f48eaf-b7d6-4964-a97b-a4b32a6aaeb3-007 completed successfully.\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Job Outcome ---\")\n",
    "ds.jobs.interpret_status(final_status, submitted_job.uuid)\n",
    "print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b2b45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to display runtime summary...\n",
      "\n",
      "Runtime Summary\n",
      "---------------\n",
      "QUEUED  time: 00:00:01\n",
      "RUNNING time: 00:00:24\n",
      "TOTAL   time: 00:02:05\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# Check against known good terminal states or the specific success state\n",
    "if final_status in [\"FINISHED\", \"FAILED\"]:  # Or just: if final_status == \"FINISHED\":\n",
    "    print(f\"\\nAttempting to display runtime summary...\")\n",
    "    try:\n",
    "        submitted_job.print_runtime_summary(verbose=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not display runtime summary: {e}\")\n",
    "else:\n",
    "    print(f\"\\nSkipping runtime summary because job ended with status: {final_status}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6437373b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching status for job 52f48eaf-b7d6-4964-a97b-a4b32a6aaeb3-007 using ds.jobs.get_status()...\n",
      "Status of job 52f48eaf-b7d6-4964-a97b-a4b32a6aaeb3-007: FINISHED\n"
     ]
    }
   ],
   "source": [
    "if \"ds\" in locals() and \"submitted_job\" in locals():  # Check if ds and a job exist\n",
    "    job_uuid_to_check = submitted_job.uuid  # Or any other job UUID string\n",
    "    try:\n",
    "        print(\n",
    "            f\"\\nFetching status for job {job_uuid_to_check} using ds.jobs.get_status()...\"\n",
    "        )\n",
    "        current_status = ds.jobs.get_status(job_uuid_to_check)\n",
    "        print(f\"Status of job {job_uuid_to_check}: {current_status}\")\n",
    "    except JobMonitorError as e:\n",
    "        print(f\"Error getting job status: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "else:\n",
    "    print(\n",
    "        \"DSClient ('ds') or submitted_job not initialized. Cannot demonstrate ds.jobs.get_status().\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a722b7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Last Status Message for Job 52f48eaf-b7d6-4964-a97b-a4b32a6aaeb3-007 ---\n",
      "Message: Setting job status to FINISHED.\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display Last Job Status Message\n",
    "if \"submitted_job\" in locals():\n",
    "    print(f\"\\n--- Last Status Message for Job {submitted_job.uuid} ---\")\n",
    "    last_msg = submitted_job.last_message\n",
    "    if last_msg:\n",
    "        print(f\"Message: {last_msg}\")\n",
    "    else:\n",
    "        print(\"No last status message available for this job.\")\n",
    "    print(\"-------------------------------------------------\")\n",
    "else:\n",
    "    print(\"\\nSkipping last status message display (job not submitted).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d39ee5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Job Output/Error for 52f48eaf-b7d6-4964-a97b-a4b32a6aaeb3-007 (Status: FINISHED) ---\n",
      "Attempting to fetch content of 'tapisjob.out' from job archive...\n",
      "Returning last 50 lines of 'tapisjob.out'.\n",
      "\n",
      "--- Last 50 lines of tapisjob.out ---\n",
      "TACC:  Starting parallel tasks... \n",
      "[2025-06-04 08:19:09.625] [main] [info] git revision: 18f353fee2ac6735e4f53c9498e7976746b04055\n",
      "[2025-06-04 08:19:09.648] [MPMBase] [warning] /work2/05873/kks32/stampede3/mpm/include/solvers/mpm_base.tcc #71: Velocity update parameter is not specified, using default as false\n",
      "[2025-06-04 08:19:09.648] [MPMBase] [warning] /work2/05873/kks32/stampede3/mpm/include/solvers/mpm_base.tcc #94: No math functions are defined\n",
      "[2025-06-04 08:19:09.648] [MPMBase] [warning] /work2/05873/kks32/stampede3/mpm/include/solvers/mpm_base.tcc #135: No VTK variables were specified, none will be generated\n",
      "[2025-06-04 08:19:09.648] [MPMBase] [warning] /work2/05873/kks32/stampede3/mpm/include/solvers/mpm_base.tcc #166: No VTK statevariable were specified, none will be generated\n",
      "[2025-06-04 08:19:09.648] [MPMExplicit] [info] MPM analysis type MPMExplicit2D\n",
      "[2025-06-04 08:19:09.649] [MPMExplicit] [warning] /work2/05873/kks32/stampede3/mpm/include/solvers/mpm_base.tcc #193: Check duplicates, not specified setting default as true\n",
      "[2025-06-04 08:19:09.650] [MPMExplicit] [info] Rank 0 Read nodes: 1 ms\n",
      "[2025-06-04 08:19:09.653] [MPMExplicit] [warning] #831: Euler angles are undefined Euler angles JSON not found \n",
      "[2025-06-04 08:19:09.653] [MPMExplicit] [warning] #935: Friction conditions are undefined Friction constraints JSON not found \n",
      "[2025-06-04 08:19:09.655] [MPMExplicit] [warning] #960: Cell entity sets are undefined Cell sets are not properly assigned \n",
      "[2025-06-04 08:19:09.655] [MPMExplicit] [info] Rank 0 Read cells: 1 ms\n",
      "[2025-06-04 08:19:09.657] [MPMExplicit] [info] Rank 0 Generate particles: 1 ms\n",
      "[2025-06-04 08:19:09.657] [MPMExplicit] [warning] #987: Particle cells are undefined Particle cells JSON not found \n",
      "[2025-06-04 08:19:09.665] [MPMExplicit] [info] Rank 0 Locate particles: 8 ms\n",
      "[2025-06-04 08:19:09.665] [MPMExplicit] [warning] #1012: Particle volumes are undefined Particle volumes JSON not found \n",
      "[2025-06-04 08:19:09.665] [MPMExplicit] [warning] #1082: Particle stresses are undefined Particle stresses JSON not found \n",
      "[2025-06-04 08:19:09.665] [MPMExplicit] [info] Rank 0 Read volume, velocity and stresses: 0 ms\n",
      "[2025-06-04 08:19:09.666] [MPMExplicit] [warning] #1109: Particle sets are undefined Particle set creation failed \n",
      "[2025-06-04 08:19:09.666] [MPMExplicit] [warning] #1053: Particle velocity constraints are undefined Particle velocity constraints JSON not found \n",
      "[2025-06-04 08:19:09.666] [MPMExplicit] [info] Rank 0 Create particle sets: 0 ms\n",
      "[2025-06-04 08:19:09.666] [MPMExplicit] [warning] /work2/05873/kks32/stampede3/mpm/include/solvers/mpm_base.tcc #388: Material sets are not specified\n",
      "[2025-06-04 08:19:09.666] [MPMExplicit] [warning] No particle surface traction is defined for the analysis\n",
      "[2025-06-04 08:19:09.666] [MPMExplicit] [warning] No concentrated nodal force is defined for the analysis\n",
      "[2025-06-04 08:19:09.666] [MPMExplicit] [info] Step: 0 of 10.\n",
      "\n",
      "[2025-06-04 08:19:09.783] [MPMExplicit] [info] Step: 1 of 10.\n",
      "\n",
      "[2025-06-04 08:19:09.805] [MPMExplicit] [info] Step: 2 of 10.\n",
      "\n",
      "[2025-06-04 08:19:09.826] [MPMExplicit] [info] Step: 3 of 10.\n",
      "\n",
      "[2025-06-04 08:19:09.845] [MPMExplicit] [info] Step: 4 of 10.\n",
      "\n",
      "[2025-06-04 08:19:09.864] [MPMExplicit] [info] Step: 5 of 10.\n",
      "\n",
      "[2025-06-04 08:19:09.884] [MPMExplicit] [info] Step: 6 of 10.\n",
      "\n",
      "[2025-06-04 08:19:09.905] [MPMExplicit] [info] Step: 7 of 10.\n",
      "\n",
      "[2025-06-04 08:19:09.927] [MPMExplicit] [info] Step: 8 of 10.\n",
      "\n",
      "[2025-06-04 08:19:09.947] [MPMExplicit] [info] Step: 9 of 10.\n",
      "\n",
      "[2025-06-04 08:19:09.968] [MPMExplicit] [info] Rank 0, Explicit USF solver duration: 302 ms\n",
      "TACC:  Shutdown complete. Exiting. \n",
      "+++ date\n",
      "++ echo 'Job  execution finished at: Wed Jun  4 08:19:10 AM CDT 2025'\n",
      "Job  execution finished at: Wed Jun  4 08:19:10 AM CDT 2025\n",
      "------------------------------------\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display job output if in a terminal state\n",
    "if \"submitted_job\" in locals() and final_status in submitted_job.TERMINAL_STATES:\n",
    "    print(\n",
    "        f\"\\n--- Job Output/Error for {submitted_job.uuid} (Status: {final_status}) ---\"\n",
    "    )\n",
    "    max_output_lines = 50  # Number of lines to display from the end of the files\n",
    "\n",
    "    # Attempt to get standard output\n",
    "    try:\n",
    "        stdout_content = submitted_job.get_output_content(\n",
    "            \"tapisjob.out\",\n",
    "            max_lines=max_output_lines,\n",
    "            missing_ok=False,  # .out should ideally always exist\n",
    "        )\n",
    "        if stdout_content is not None:\n",
    "            print(f\"\\n--- Last {max_output_lines} lines of tapisjob.out ---\")\n",
    "            print(stdout_content)\n",
    "            print(\"------------------------------------\")\n",
    "        else:\n",
    "            print(\"\\n[INFO] tapisjob.out was not found or is empty.\")\n",
    "    except FileOperationError as e:\n",
    "        print(f\"\\n[ERROR] Could not retrieve tapisjob.out: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERROR] Unexpected error retrieving tapisjob.out: {e}\")\n",
    "\n",
    "    # If job failed, also try to get standard error (tapisjob.err might not always be separate)\n",
    "    if final_status in [\n",
    "        \"FAILED\",\n",
    "        \"ARCHIVING_FAILED\",\n",
    "    ]:  # Add other failure states if needed\n",
    "        try:\n",
    "            stderr_content = submitted_job.get_output_content(\n",
    "                \"tapisjob.err\",  # This file might not exist if stderr is redirected to .out\n",
    "                max_lines=max_output_lines,\n",
    "                missing_ok=True,  # Okay if .err doesn't exist\n",
    "            )\n",
    "            if stderr_content is not None:  # Only print if found and not empty\n",
    "                print(f\"\\n--- Last {max_output_lines} lines of tapisjob.err ---\")\n",
    "                print(stderr_content)\n",
    "                print(\"------------------------------------\")\n",
    "            else:\n",
    "                print(\n",
    "                    \"\\n[INFO] tapisjob.err was not found (this is common if errors are in tapisjob.out).\"\n",
    "                )\n",
    "        except FileOperationError as e:\n",
    "            print(f\"\\n[ERROR] Could not retrieve tapisjob.err: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n[ERROR] Unexpected error retrieving tapisjob.err: {e}\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "else:\n",
    "    print(\n",
    "        \"\\nSkipping job output display (job not submitted or not in a terminal state).\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fe8ac5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to access archive information...\n",
      "Job Archive Tapis URI: tapis://stampede3/work2/05873/kks32/stampede3/tapis-jobs-archive/2025-06-04Z/mpm-s3-20250604_081741-52f48eaf-b7d6-4964-a97b-a4b32a6aaeb3-007\n",
      "\n",
      "Listing archive contents (root):\n",
      "Listing files in system 'stampede3' at path 'work2/05873/kks32/stampede3/tapis-jobs-archive/2025-06-04Z/mpm-s3-20250604_081741-52f48eaf-b7d6-4964-a97b-a4b32a6aaeb3-007'...\n",
      "Found 5 items.\n",
      "- inputDirectory (Type: dir, Size: 4096 bytes, Modified: 2025-06-04T13:19:50Z)\n",
      "- tapisjob.env (Type: file, Size: 1518 bytes, Modified: 2025-06-04T13:19:49Z)\n",
      "- tapisjob.out (Type: file, Size: 3973 bytes, Modified: 2025-06-04T13:19:49Z)\n",
      "- tapisjob.sh (Type: file, Size: 1205 bytes, Modified: 2025-06-04T13:19:50Z)\n",
      "- tapisjob_app.sh (Type: file, Size: 263 bytes, Modified: 2025-06-04T13:19:49Z)\n"
     ]
    }
   ],
   "source": [
    "# if final_status in TAPIS_TERMINAL_STATES and final_status != STATUS_UNKNOWN: # Check if it's a known end state\n",
    "print(f\"\\nAttempting to access archive information...\")\n",
    "try:\n",
    "    archive_uri = submitted_job.archive_uri\n",
    "    if archive_uri:\n",
    "        print(f\"Job Archive Tapis URI: {archive_uri}\")\n",
    "        print(\"\\nListing archive contents (root):\")\n",
    "        outputs = ds.files.list(archive_uri)\n",
    "        if outputs:\n",
    "            for item in outputs:\n",
    "                print(\n",
    "                    f\"- {item.name} (Type: {item.type}, Size: {item.size} bytes, Modified: {item.lastModified})\"\n",
    "                )\n",
    "        else:\n",
    "            print(\"No files found in the archive root directory.\")\n",
    "    else:\n",
    "        print(\"Archive URI not available for this job.\")\n",
    "except FileOperationError as e:\n",
    "    print(f\"Could not list archive files: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while accessing archive information: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721b9c95",
   "metadata": {},
   "source": [
    "## Apps Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "335379df-6e64-475e-8c14-5c8c748e818e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 92 total apps.\n"
     ]
    }
   ],
   "source": [
    "# Find all apps (less verbose)\n",
    "all_apps = ds.apps.find(\"\", verbose=False)\n",
    "print(f\"Found {len(all_apps)} total apps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5574dcd-2c32-4822-be12-fe558747ebde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 2 matching apps:\n",
      "- mpm (Version: 1.1.0, Owner: wma_prtl)\n",
      "- mpm-s3 (Version: 1.0, Owner: wma_prtl)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find MPM apps specifically\n",
    "mpm_apps = ds.apps.find(\"mpm\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37074448-fe54-4aab-b458-cfe9dc1a5101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "App Details:\n",
      "  ID: opensees-express\n",
      "  Version: latest\n",
      "  Owner: wma_prtl\n",
      "  Execution System: wma-exec-01\n",
      "  Description: OpenSees-EXPRESS provides users with a sequential OpenSees interpreter. It is ideal to run small sequential scripts on DesignSafe resources freeing up your own machine.\n",
      "App Description: \n",
      "containerImage: tapis://cloud.data/corral/tacc/aci/CEP/applications/v3/opensees/latest/OpenSees-EXPRESS/opensees_express.zip\n",
      "created: 2025-02-20T18:41:03.661272Z\n",
      "deleted: False\n",
      "description: OpenSees-EXPRESS provides users with a sequential OpenSees interpreter. It is ideal to run small sequential scripts on DesignSafe resources freeing up your own machine.\n",
      "enabled: True\n",
      "id: opensees-express\n",
      "isPublic: True\n",
      "jobAttributes: \n",
      "archiveOnAppError: True\n",
      "archiveSystemDir: /tmp/${JobOwner}/tapis-jobs-archive/${JobCreateDate}/${JobName}-${JobUUID}\n",
      "archiveSystemId: cloud.data\n",
      "cmdPrefix: None\n",
      "coresPerNode: 1\n",
      "description: None\n",
      "dtnSystemInputDir: !tapis_not_set\n",
      "dtnSystemOutputDir: !tapis_not_set\n",
      "dynamicExecSystem: False\n",
      "execSystemConstraints: None\n",
      "execSystemExecDir: ${JobWorkingDir}\n",
      "execSystemId: wma-exec-01\n",
      "execSystemInputDir: ${JobWorkingDir}\n",
      "execSystemLogicalQueue: None\n",
      "execSystemOutputDir: ${JobWorkingDir}\n",
      "fileInputArrays: []\n",
      "fileInputs: [\n",
      "autoMountLocal: True\n",
      "description: Input directory that includes the tcl script as well as any other required files. Example input is in tapis://designsafe.storage.community/app_examples/opensees/OpenSeesEXPRESS\n",
      "envKey: inputDirectory\n",
      "inputMode: REQUIRED\n",
      "name: Input Directory\n",
      "notes: \n",
      "selectionMode: directory\n",
      "sourceUrl: None\n",
      "targetPath: *]\n",
      "isMpi: False\n",
      "maxMinutes: 1440\n",
      "memoryMB: 100\n",
      "mpiCmd: None\n",
      "nodeCount: 1\n",
      "parameterSet: \n",
      "appArgs: []\n",
      "archiveFilter: \n",
      "excludes: ['opensees-express.zip', 'tapisjob.env']\n",
      "includeLaunchFiles: True\n",
      "includes: []\n",
      "containerArgs: []\n",
      "envVariables: [\n",
      "description: Choose the OpenSees binary to use.\n",
      "inputMode: REQUIRED\n",
      "key: mainProgram\n",
      "notes: \n",
      "enum_values: [\n",
      "OpenSees: OpenSees, \n",
      "OpenSeesSP: OpenSeesSP, \n",
      "OpenSeesMP: OpenSeesMP]\n",
      "label: Main Program\n",
      "value: OpenSees, \n",
      "description: The filename of the OpenSees TCL script to execute, e.g. \"freeFieldEffective.tcl\".\n",
      "inputMode: REQUIRED\n",
      "key: tclScript\n",
      "notes: \n",
      "inputType: fileInput\n",
      "label: Main Script\n",
      "value: ]\n",
      "logConfig: \n",
      "stderrFilename: \n",
      "stdoutFilename: \n",
      "schedulerOptions: []\n",
      "subscriptions: []\n",
      "tags: []\n",
      "jobType: FORK\n",
      "locked: False\n",
      "maxJobs: 2147483647\n",
      "maxJobsPerUser: 2147483647\n",
      "notes: \n",
      "category: Simulation\n",
      "helpUrl: https://www.designsafe-ci.org/user-guide/tools/simulation/#opensees-user-guide\n",
      "hideNodeCountAndCoresPerNode: True\n",
      "icon: OpenSees\n",
      "isInteractive: False\n",
      "label: OpenSees-EXPRESS (VM)\n",
      "owner: wma_prtl\n",
      "runtime: ZIP\n",
      "runtimeOptions: None\n",
      "runtimeVersion: None\n",
      "sharedAppCtx: wma_prtl\n",
      "sharedWithUsers: []\n",
      "strictFileInputs: True\n",
      "tags: ['portalName: DesignSafe', 'portalName: CEP']\n",
      "tenant: designsafe\n",
      "updated: 2025-02-26T21:17:36.417952Z\n",
      "uuid: 30cb1fa1-e7c7-44a8-a0e8-d2f64043fc65\n",
      "version: latest\n",
      "versionEnabled: True\n"
     ]
    }
   ],
   "source": [
    "# Get details for the specific MPM app we want to use\n",
    "app_id_to_use = \"opensees-express\"\n",
    "app_details = ds.apps.get_details(app_id_to_use, verbose=True)\n",
    "\n",
    "if not app_details:\n",
    "    raise SystemExit(\n",
    "        f\"Could not find details for app '{app_id_to_use}'. Please check the app ID.\"\n",
    "    )\n",
    "# Print the app details\n",
    "\n",
    "print(f\"App Description: {app_details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9aaef98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- System Queue Information ---\n",
      "\n",
      "Fetching queue information for system 'frontera'...\n",
      "Found 10 batch logical queues for system 'frontera':\n",
      "  - Name: flex (HPC Queue: flex, Max Jobs: -1, Max User Jobs: N/A, Max Mins: 2880, Max Nodes: 128)\n",
      "  - Name: development (HPC Queue: development, Max Jobs: -1, Max User Jobs: N/A, Max Mins: 120, Max Nodes: 40)\n",
      "  - Name: normal (HPC Queue: normal, Max Jobs: -1, Max User Jobs: N/A, Max Mins: 2880, Max Nodes: 512)\n",
      "  - Name: large (HPC Queue: large, Max Jobs: -1, Max User Jobs: N/A, Max Mins: 2880, Max Nodes: 2048)\n",
      "  - Name: debug (HPC Queue: debug, Max Jobs: -1, Max User Jobs: N/A, Max Mins: 2880, Max Nodes: 8368)\n",
      "  - Name: rtx (HPC Queue: rtx, Max Jobs: -1, Max User Jobs: N/A, Max Mins: 2880, Max Nodes: 22)\n",
      "  - Name: rtx-dev (HPC Queue: rtx-dev, Max Jobs: -1, Max User Jobs: N/A, Max Mins: 120, Max Nodes: 2)\n",
      "  - Name: nvdimm (HPC Queue: nvdimm, Max Jobs: -1, Max User Jobs: N/A, Max Mins: 120, Max Nodes: 4)\n",
      "  - Name: small (HPC Queue: small, Max Jobs: -1, Max User Jobs: N/A, Max Mins: 2880, Max Nodes: 2)\n",
      "  - Name: grace (HPC Queue: grace, Max Jobs: -1, Max User Jobs: N/A, Max Mins: 7200, Max Nodes: 30)\n",
      "\n",
      "Does 'development' queue exist on Frontera? True\n",
      "\n",
      "Fetching queue information for system 'non-existent-system'...\n",
      "Error getting system info: Failed to retrieve queues for system 'non-existent-system': message: SYSAPI_NOT_FOUND Record not found. jwtTenant: designsafe jwtUser: kks32 OboTenant: designsafe OboUser: kks32 System: non-existent-system\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Example: List Queues for Frontera ---\n",
    "try:\n",
    "    print(\"\\n--- System Queue Information ---\")\n",
    "    frontera_queues = ds.systems.list_queues(\"frontera\")\n",
    "    # You can now inspect the 'frontera_queues' list\n",
    "    # Example: Find if 'development' queue exists\n",
    "    dev_queue_exists = any(q.name == \"development\" for q in frontera_queues)\n",
    "    print(f\"Does 'development' queue exist on Frontera? {dev_queue_exists}\")\n",
    "\n",
    "    # Example: List queues for a non-existent system\n",
    "    ds.systems.list_queues(\"non-existent-system\")  # This would raise SystemInfoError\n",
    "\n",
    "except SystemInfoError as e:\n",
    "    print(f\"Error getting system info: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fb073a",
   "metadata": {},
   "source": [
    "## Verify TAPIS paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e074a3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translating and verifying path: /MyData/mpm-benchmarks/2d/uniaxial_stress/\n",
      "Translated '/MyData/mpm-benchmarks/2d/uniaxial_stress/' to 'tapis://designsafe.storage.default/kks32/mpm-benchmarks/2d/uniaxial_stress/' using t.username\n",
      "Verifying existence of translated path: tapis://designsafe.storage.default/kks32/mpm-benchmarks/2d/uniaxial_stress/\n",
      "Checking system 'designsafe.storage.default' for path 'kks32/mpm-benchmarks/2d/uniaxial_stress/'...\n",
      "Verification successful: Path exists.\n",
      "Input Directory Tapis URI (verified): tapis://designsafe.storage.default/kks32/mpm-benchmarks/2d/uniaxial_stress/\n",
      "\n",
      "Translating and verifying non-existent path: /MyData/this/path/does/not/exist/\n",
      "Translated '/MyData/this/path/does/not/exist/' to 'tapis://designsafe.storage.default/kks32/this/path/does/not/exist/' using t.username\n",
      "Verifying existence of translated path: tapis://designsafe.storage.default/kks32/this/path/does/not/exist/\n",
      "Checking system 'designsafe.storage.default' for path 'kks32/this/path/does/not/exist/'...\n",
      "Error during path translation/verification: Verification error for path 'kks32/this/path/does/not/exist/' on system 'designsafe.storage.default': message: FILES_CLIENT_SSH_NOT_FOUND Path not found. OboTenant: designsafe OboUser: kks32 System: designsafe.storage.default EffectiveUser: kks32 Host: cloud.data.tacc.utexas.edu RootDir: /data/designsafe/mydata Path: kks32/this/path/does/not/exist\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Stopping notebook due to path verification error.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Stopping notebook due to path verification error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishna/Library/Caches/pypoetry/virtualenvs/dapi-ptztLUqK-py3.13/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# --- Translate Path with Verification ---\n",
    "ds_path: str = \"/MyData/mpm-benchmarks/2d/uniaxial_stress/\"\n",
    "ds_path_nonexistent: str = \"/MyData/this/path/does/not/exist/\"\n",
    "\n",
    "try:\n",
    "    # Translate and verify the existing path\n",
    "    print(f\"\\nTranslating and verifying path: {ds_path}\")\n",
    "    input_uri = ds.files.translate_path_to_uri(ds_path, verify_exists=True)\n",
    "    print(f\"Input Directory Tapis URI (verified): {input_uri}\")\n",
    "\n",
    "    # Example: Try translating a non-existent path with verification (will raise error)\n",
    "    print(f\"\\nTranslating and verifying non-existent path: {ds_path_nonexistent}\")\n",
    "    input_uri_bad = ds.files.translate_path_to_uri(\n",
    "        ds_path_nonexistent, verify_exists=True\n",
    "    )\n",
    "    print(f\"This line should not be reached.\")\n",
    "\n",
    "except FileOperationError as e:\n",
    "    print(f\"Error during path translation/verification: {e}\")\n",
    "    # Decide how to handle the error (e.g., stop notebook, use default, etc.)\n",
    "    # For this example, we'll stop if verification fails.\n",
    "    raise SystemExit(\"Stopping notebook due to path verification error.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during path translation: {e}\")\n",
    "    raise SystemExit(\"Stopping notebook due to unexpected path translation error.\")"
   ]
  }
 ],
 "metadata": {
  "IMAGE_NAME": "taccsciapps/ds-nb-img:base-0.2.1",
  "UUID": "ad99fe82-d690-11ec-8bc3-165d4cd45074",
  "kernelspec": {
   "display_name": "dapi-ptztLUqK-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
