{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenFOAM Example with DAPI\n",
    "## Accessing OpenFOAM (Version 6 or Version 7) using DesignSafe API (DAPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install DesignSafe API (DAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAPI installation\n",
    "!pip uninstall dapi --yes --quiet\n",
    "!pip install dapi --user --quiet\n",
    "\n",
    "# Uncomment to install development version\n",
    "# !pip install git+https://github.com/DesignSafe-CI/dapi.git@dev --user --quiet\n",
    "\n",
    "# Uncomment to install editable local version\n",
    "# !pip install -e ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import DAPI and Initialize Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Import DAPI components\n",
    "from dapi import (\n",
    "    DSClient,\n",
    "    SubmittedJob,\n",
    "    interpret_job_status,\n",
    "    AppDiscoveryError,\n",
    "    FileOperationError,\n",
    "    JobSubmissionError,\n",
    "    SystemInfoError,\n",
    "    JobMonitorError,\n",
    "    STATUS_TIMEOUT,\n",
    "    STATUS_UNKNOWN,\n",
    "    TAPIS_TERMINAL_STATES,\n",
    ")\n",
    "\n",
    "print(\"DAPI imports successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DAPI client\n",
    "try:\n",
    "    print(\"Initializing DSClient...\")\n",
    "    ds = DSClient()\n",
    "    print(\"DSClient initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Initialization failed: {e}\")\n",
    "    raise SystemExit(\"Stopping notebook due to client initialization failure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover OpenFOAM Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find OpenFOAM applications\n",
    "try:\n",
    "    print(\"Searching for OpenFOAM applications...\")\n",
    "    openfoam_apps = ds.apps.find(\"openfoam\", verbose=True)\n",
    "\n",
    "    if not openfoam_apps:\n",
    "        print(\"No OpenFOAM applications found.\")\n",
    "        raise SystemExit(\"No OpenFOAM apps available.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error finding OpenFOAM apps: {e}\")\n",
    "    raise SystemExit(\"Failed to discover OpenFOAM applications.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get details for OpenFOAM application\n",
    "app_id = \"openfoam-7.0u4\"  # Use the same app as the original example\n",
    "\n",
    "try:\n",
    "    print(f\"Getting details for app: {app_id}\")\n",
    "    app_details = ds.apps.get_details(app_id, verbose=True)\n",
    "\n",
    "    if not app_details:\n",
    "        raise SystemExit(f\"Could not find details for app '{app_id}'.\")\n",
    "\n",
    "    print(f\"\\nApp Description: {app_details.description}\")\n",
    "    print(f\"App Version: {app_details.version}\")\n",
    "    print(f\"Execution System: {app_details.jobAttributes.execSystemId}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error getting app details: {e}\")\n",
    "    raise SystemExit(\"Failed to get OpenFOAM app details.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustrative case\n",
    "### Simulation of the wind flow around a square cross-section of the building using RANS model\n",
    ">Case directory: DH1_run contains $0$, *constant* and *system* directories.\n",
    "\n",
    "![frame.png](attachment:frame.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesh generation using the *blockMesh* utility \n",
    "> Note: The grid resolution in the plot doesn't meet the requirement for running RANS simulations. This is only for an illustrative case.\n",
    "\n",
    "![Mesh.png](attachment:Mesh.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display blockMeshDict file content (if available locally)\n",
    "try:\n",
    "    with open(\"DH1_run/system/blockMeshDict\", \"r\") as f:\n",
    "        file_contents = f.read()\n",
    "        print(file_contents)\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        \"blockMeshDict file not found locally. Please ensure the case directory is available.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display velocity boundary conditions (if available locally)\n",
    "try:\n",
    "    with open(\"DH1_run/0/U\", \"r\") as f:\n",
    "        file_contents = f.read()\n",
    "        print(file_contents)\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        \"Velocity file (U) not found locally. Please ensure the case directory is available.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display turbulence properties (if available locally)\n",
    "try:\n",
    "    with open(\"DH1_run/constant/turbulenceProperties\", \"r\") as f:\n",
    "        file_contents = f.read()\n",
    "        print(file_contents)\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        \"turbulenceProperties file not found locally. Please ensure the case directory is available.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the OpenFOAM run configuration\n",
    "(Reference:\n",
    "Harish, Ajay Bangalore; Govindjee, Sanjay; McKenna, Frank (2020) \"CFD Notebooks (Beginner).\" DesignSafe-CI. https://doi.org/10.17603/ds2-w2x6-nm09.)\n",
    "\n",
    "> Specify the number of nodes and processors for parallel computing <br>\n",
    "> Select a solver <br>\n",
    "> Change to your input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "ds_path = \"/MyData/OpenFOAM_examples/DH1_run\"  # Update with your actual path\n",
    "max_job_minutes = 120  # 2 hours\n",
    "tacc_allocation = \"ASC25049\"  # Update with your allocation\n",
    "\n",
    "# Job configuration\n",
    "job_name = \"OpenFOAM-DAPI-Demo\"\n",
    "node_count = 1\n",
    "cores_per_node = 2\n",
    "solver = \"pisoFoam\"\n",
    "mesh_option = \"On\"\n",
    "decomp_option = \"On\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate local path to Tapis URI\n",
    "try:\n",
    "    print(f\"Translating path: {ds_path}\")\n",
    "    input_uri = ds.files.translate_path_to_uri(ds_path, verify_exists=True)\n",
    "    print(f\"Input Directory Tapis URI: {input_uri}\")\n",
    "except FileOperationError as e:\n",
    "    print(f\"Error translating/verifying path '{ds_path}': {e}\")\n",
    "    print(\n",
    "        \"Please update the ds_path variable with the correct path to your OpenFOAM case directory.\"\n",
    "    )\n",
    "    raise SystemExit(\"Stopping due to path error.\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "    raise SystemExit(\"Stopping due to unexpected error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Job Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate job request using DAPI\n",
    "try:\n",
    "    print(\"\\nGenerating job request dictionary...\")\n",
    "    job_dict = ds.jobs.generate_request(\n",
    "        app_id=app_id,\n",
    "        input_dir_uri=input_uri,\n",
    "        max_minutes=max_job_minutes,\n",
    "        allocation=tacc_allocation,\n",
    "        job_name=job_name,\n",
    "    )\n",
    "\n",
    "    # Customize job parameters for OpenFOAM\n",
    "    job_dict[\"nodeCount\"] = node_count\n",
    "    job_dict[\"coresPerNode\"] = cores_per_node\n",
    "\n",
    "    # Add OpenFOAM-specific parameters\n",
    "    if \"parameterSet\" not in job_dict:\n",
    "        job_dict[\"parameterSet\"] = {}\n",
    "    if \"appArgs\" not in job_dict[\"parameterSet\"]:\n",
    "        job_dict[\"parameterSet\"][\"appArgs\"] = []\n",
    "\n",
    "    # Add OpenFOAM parameters (mesh, solver, decomp)\n",
    "    openfoam_params = [\n",
    "        {\"name\": \"mesh\", \"arg\": mesh_option},\n",
    "        {\"name\": \"solver\", \"arg\": solver},\n",
    "        {\"name\": \"decomp\", \"arg\": decomp_option},\n",
    "    ]\n",
    "\n",
    "    job_dict[\"parameterSet\"][\"appArgs\"].extend(openfoam_params)\n",
    "\n",
    "    print(\"\\n--- Generated Job Request Dictionary ---\")\n",
    "    print(json.dumps(job_dict, indent=2, default=str))\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "except (AppDiscoveryError, ValueError, JobSubmissionError) as e:\n",
    "    print(f\"Error generating job request: {e}\")\n",
    "    raise SystemExit(\"Stopping due to job request generation error.\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error during job request generation: {e}\")\n",
    "    raise SystemExit(\"Stopping due to unexpected generation error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Job to TACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the job\n",
    "try:\n",
    "    print(\"\\nSubmitting the job request...\")\n",
    "    submitted_job = ds.jobs.submit_request(job_dict)\n",
    "    print(f\"Job Submitted Successfully!\")\n",
    "    print(f\"Job UUID: {submitted_job.uuid}\")\n",
    "\n",
    "except JobSubmissionError as e:\n",
    "    print(f\"Job submission failed: {e}\")\n",
    "    print(\"\\n--- Failed Job Request ---\")\n",
    "    print(json.dumps(job_dict, indent=2, default=str))\n",
    "    print(\"--------------------------\")\n",
    "    raise SystemExit(\"Stopping due to job submission error.\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error during job submission: {e}\")\n",
    "    raise SystemExit(\"Stopping due to unexpected submission error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor job execution\n",
    "if \"submitted_job\" not in locals():\n",
    "    print(\"Error: submitted_job not found.\")\n",
    "    raise SystemExit(\"Stopping notebook.\")\n",
    "\n",
    "# Monitor the job with 30-second intervals\n",
    "try:\n",
    "    print(\"\\nMonitoring job execution...\")\n",
    "    final_status = submitted_job.monitor(interval=30)\n",
    "    print(f\"\\nJob {submitted_job.uuid} monitoring finished.\")\n",
    "    print(f\"Final status: {final_status}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during job monitoring: {e}\")\n",
    "    # Continue even if monitoring fails - we can check status manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Job Status and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret job outcome\n",
    "try:\n",
    "    print(\"\\n--- Job Outcome ---\")\n",
    "    ds.jobs.interpret_status(final_status, submitted_job.uuid)\n",
    "    print(\"-------------------\")\n",
    "except Exception as e:\n",
    "    print(f\"Error interpreting job status: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display runtime summary for completed jobs\n",
    "if final_status in [\"FINISHED\", \"FAILED\"]:\n",
    "    print(f\"\\nAttempting to display runtime summary...\")\n",
    "    try:\n",
    "        submitted_job.print_runtime_summary(verbose=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not display runtime summary: {e}\")\n",
    "else:\n",
    "    print(f\"\\nSkipping runtime summary because job ended with status: {final_status}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current job status\n",
    "try:\n",
    "    current_status = ds.jobs.get_status(submitted_job.uuid)\n",
    "    print(f\"\\nCurrent status of job {submitted_job.uuid}: {current_status}\")\n",
    "except JobMonitorError as e:\n",
    "    print(f\"Error getting job status: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Job Output and Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display job output if in terminal state\n",
    "if \"submitted_job\" in locals() and final_status in submitted_job.TERMINAL_STATES:\n",
    "    print(f\"\\n--- Job Output for {submitted_job.uuid} (Status: {final_status}) ---\")\n",
    "    max_output_lines = 50\n",
    "\n",
    "    # Get standard output\n",
    "    try:\n",
    "        stdout_content = submitted_job.get_output_content(\n",
    "            \"tapisjob.out\", max_lines=max_output_lines, missing_ok=False\n",
    "        )\n",
    "        if stdout_content is not None:\n",
    "            print(f\"\\n--- Last {max_output_lines} lines of tapisjob.out ---\")\n",
    "            print(stdout_content)\n",
    "            print(\"------------------------------------\")\n",
    "        else:\n",
    "            print(\"\\n[INFO] tapisjob.out was not found or is empty.\")\n",
    "    except FileOperationError as e:\n",
    "        print(f\"\\n[ERROR] Could not retrieve tapisjob.out: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERROR] Unexpected error retrieving tapisjob.out: {e}\")\n",
    "\n",
    "    # Get error output for failed jobs\n",
    "    if final_status in [\"FAILED\", \"ARCHIVING_FAILED\"]:\n",
    "        try:\n",
    "            stderr_content = submitted_job.get_output_content(\n",
    "                \"tapisjob.err\", max_lines=max_output_lines, missing_ok=True\n",
    "            )\n",
    "            if stderr_content is not None:\n",
    "                print(f\"\\n--- Last {max_output_lines} lines of tapisjob.err ---\")\n",
    "                print(stderr_content)\n",
    "                print(\"------------------------------------\")\n",
    "            else:\n",
    "                print(\"\\n[INFO] tapisjob.err was not found.\")\n",
    "        except FileOperationError as e:\n",
    "            print(f\"\\n[ERROR] Could not retrieve tapisjob.err: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n[ERROR] Unexpected error retrieving tapisjob.err: {e}\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "else:\n",
    "    print(\"\\nSkipping job output display (job not in terminal state).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access job archive\n",
    "try:\n",
    "    print(f\"\\nAttempting to access archive information...\")\n",
    "    archive_uri = submitted_job.archive_uri\n",
    "    if archive_uri:\n",
    "        print(f\"Job Archive Tapis URI: {archive_uri}\")\n",
    "        print(\"\\nListing archive contents (root):\")\n",
    "        outputs = ds.files.list(archive_uri)\n",
    "        if outputs:\n",
    "            for item in outputs:\n",
    "                print(\n",
    "                    f\"- {item.name} (Type: {item.type}, Size: {item.size} bytes, Modified: {item.lastModified})\"\n",
    "                )\n",
    "        else:\n",
    "            print(\"No files found in the archive root directory.\")\n",
    "    else:\n",
    "        print(\"Archive URI not available for this job.\")\n",
    "except FileOperationError as e:\n",
    "    print(f\"Could not list archive files: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error while accessing archive information: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing\n",
    "### Using *ParaView* to visualize the flow fields\n",
    "*ParaView* can read *OpenFOAM* files using *.foam*.\n",
    "\n",
    ">If .foam is not included in the case directory, you can copy the archive results:\n",
    "\n",
    ">**import shutil**\n",
    "\n",
    ">**shutil.copy2('case_directory/foam.foam', 'destination_path')**\n",
    "\n",
    "![ParaView.png](attachment:ParaView.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the time series of the force coefficients\n",
    "> Update the path to point to your job's archive directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example code for processing force coefficients\n",
    "# Update the path based on your job's archive location\n",
    "try:\n",
    "    # You would need to download or access the specific results file\n",
    "    # from the job archive. This is just an example structure.\n",
    "\n",
    "    # For now, we'll show the structure that would be used:\n",
    "    print(\"To plot force coefficients:\")\n",
    "    print(\"1. Access the job archive using the archive_uri\")\n",
    "    print(\"2. Download the postProcessing/forceCoeffs/0/forceCoeffs.dat file\")\n",
    "    print(\"3. Use the plotting code below with the actual data\")\n",
    "\n",
    "    # Example plotting code (commented out since we don't have actual data)\n",
    "    \"\"\"\n",
    "    def is_float(string):\n",
    "        try:\n",
    "            return float(string)\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    data = []\n",
    "    with open('forceCoeffs.dat', 'r') as f:\n",
    "        d = f.readlines()\n",
    "        for i in d:\n",
    "            k = i.rstrip().split(\"\\t\")\n",
    "            data.append([float(i) if is_float(i) else i for i in k]) \n",
    "\n",
    "    data = np.array(data[9:], dtype='O')\n",
    "    \n",
    "    # Plot drag coefficient\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(data[100:,0], data[100:,2])\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('$C_d$')\n",
    "    plt.title('Drag Coefficient vs Time')\n",
    "    \n",
    "    # Plot lift coefficient\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(data[100:,0], data[100:,3])\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('$C_l$')\n",
    "    plt.title('Lift Coefficient vs Time')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Note: Actual post-processing would require accessing the job results: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. **Initialize DAPI client** with authentication\n",
    "2. **Discover OpenFOAM applications** using `ds.apps.find()`\n",
    "3. **Get application details** using `ds.apps.get_details()`\n",
    "4. **Generate job requests** using `ds.jobs.generate_request()`\n",
    "5. **Submit jobs** using `ds.jobs.submit_request()`\n",
    "6. **Monitor job execution** using `submitted_job.monitor()`\n",
    "7. **Access job outputs and archives** using DAPI file operations\n",
    "\n",
    "Key differences from the Agave version:\n",
    "- Uses DAPI's modern authentication system\n",
    "- Leverages DAPI's built-in job monitoring and status interpretation\n",
    "- Provides better error handling and user feedback\n",
    "- Uses Tapis v3 APIs through DAPI's simplified interface"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}