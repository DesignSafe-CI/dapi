{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Multi-Free Field Analysis Example using DAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "This example shows how to run OpenSeesMP in DesignSafe from a jupyter notebook using the DesignSafe API (dapi).\n",
    "\n",
    "A set of four 1D profiles is analyzed using OpenSeesMP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "<img src = \"multi-freeField.png\"  height=\"400\" width=\"400\" align = \"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "# Setup DAPI and start OpenSeesMP job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!python -m pip install --upgrade numpy\n",
    "!pip install -e ../../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### Setup job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DAPI and other required libraries\n",
    "from dapi import DSClient\n",
    "import os\n",
    "import json\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful.\n",
      "DatabaseAccessor initialized. Connections will be created on first access.\n"
     ]
    }
   ],
   "source": [
    "# Initialize DesignSafe client\n",
    "ds = DSClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DesignSafe path: /home/jupyter/MyData/template-notebooks/tapis3/opensees/OpenSeesMP_multiMotion/DS_input\n",
      "Translated '/home/jupyter/MyData/template-notebooks/tapis3/opensees/OpenSeesMP_multiMotion/DS_input' to 'tapis://designsafe.storage.default/kks32/template-notebooks/tapis3/opensees/OpenSeesMP_multiMotion/DS_input' using t.username\n",
      "Input URI: tapis://designsafe.storage.default/kks32/template-notebooks/tapis3/opensees/OpenSeesMP_multiMotion/DS_input\n"
     ]
    }
   ],
   "source": [
    "ds_path = \"/home/jupyter/MyData/template-notebooks/tapis3/opensees/OpenSeesMP_multiMotion/DS_input\"\n",
    "print(f\"DesignSafe path: {ds_path}\")\n",
    "input_uri = ds.files.translate_path_to_uri(ds_path)\n",
    "print(f\"Input URI: {input_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job configuration parameters\n",
    "jobname: str = \"opensees-MP-multiMotion-dapi\"\n",
    "app_id: str = \"opensees-mp-s3\"\n",
    "input_filename: str = \"Main_multiMotion.tcl\"\n",
    "control_exec_Dir: str = \"DS_input\"  # Folder with files including input_filename\n",
    "tacc_allocation: str = \"ASC25049\"  # MUST USE YOUR OWN ALLOCATION !!\n",
    "control_nodeCount: int = 1\n",
    "control_corespernode: int = 16\n",
    "max_job_minutes: int = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5286f5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating job request for app 'opensees-mp-s3'...\n",
      "Using App Details: opensees-mp-s3 vlatest\n",
      "Placing script 'Main_multiMotion.tcl' in appArgs: 'Main Script'\n",
      "Adding allocation: ASC25049\n",
      "Job request dictionary generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Generate job request dictionary using app defaults\n",
    "job_dict = ds.jobs.generate_request(\n",
    "    app_id=app_id,\n",
    "    input_dir_uri=input_uri,\n",
    "    script_filename=input_filename,\n",
    "    max_minutes=max_job_minutes,\n",
    "    allocation=tacc_allocation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated job request:\n",
      "{\n",
      "  \"name\": \"opensees-MP-multiMotion-dapi\",\n",
      "  \"appId\": \"opensees-mp-s3\",\n",
      "  \"appVersion\": \"latest\",\n",
      "  \"description\": \"Runs all the processors in parallel. Requires understanding of parallel processing and the capabilities to write parallel scripts.\",\n",
      "  \"execSystemId\": \"stampede3\",\n",
      "  \"archiveSystemId\": \"stampede3\",\n",
      "  \"archiveOnAppError\": true,\n",
      "  \"execSystemLogicalQueue\": \"skx\",\n",
      "  \"nodeCount\": 1,\n",
      "  \"coresPerNode\": 16,\n",
      "  \"maxMinutes\": 60,\n",
      "  \"memoryMB\": 192000,\n",
      "  \"isMpi\": false,\n",
      "  \"tags\": [],\n",
      "  \"fileInputs\": [\n",
      "    {\n",
      "      \"name\": \"Input Directory\",\n",
      "      \"sourceUrl\": \"tapis://designsafe.storage.default/kks32/template-notebooks/tapis3/opensees/OpenSeesMP_multiMotion/DS_input\",\n",
      "      \"autoMountLocal\": true,\n",
      "      \"targetPath\": \"inputDirectory\"\n",
      "    }\n",
      "  ],\n",
      "  \"parameterSet\": {\n",
      "    \"appArgs\": [\n",
      "      {\n",
      "        \"name\": \"Main Script\",\n",
      "        \"arg\": \"Main_multiMotion.tcl\"\n",
      "      }\n",
      "    ],\n",
      "    \"schedulerOptions\": [\n",
      "      {\n",
      "        \"name\": \"TACC Allocation\",\n",
      "        \"arg\": \"-A ASC25049\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Customize job settings\n",
    "job_dict[\"name\"] = jobname\n",
    "job_dict[\"nodeCount\"] = control_nodeCount\n",
    "job_dict[\"coresPerNode\"] = control_corespernode\n",
    "\n",
    "print(\"Generated job request:\")\n",
    "print(json.dumps(job_dict, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### Run job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Submitting Tapis Job Request ---\n",
      "{\n",
      "  \"name\": \"opensees-MP-multiMotion-dapi\",\n",
      "  \"appId\": \"opensees-mp-s3\",\n",
      "  \"appVersion\": \"latest\",\n",
      "  \"description\": \"Runs all the processors in parallel. Requires understanding of parallel processing and the capabilities to write parallel scripts.\",\n",
      "  \"execSystemId\": \"stampede3\",\n",
      "  \"archiveSystemId\": \"stampede3\",\n",
      "  \"archiveOnAppError\": true,\n",
      "  \"execSystemLogicalQueue\": \"skx\",\n",
      "  \"nodeCount\": 1,\n",
      "  \"coresPerNode\": 16,\n",
      "  \"maxMinutes\": 60,\n",
      "  \"memoryMB\": 192000,\n",
      "  \"isMpi\": false,\n",
      "  \"tags\": [],\n",
      "  \"fileInputs\": [\n",
      "    {\n",
      "      \"name\": \"Input Directory\",\n",
      "      \"sourceUrl\": \"tapis://designsafe.storage.default/kks32/template-notebooks/tapis3/opensees/OpenSeesMP_multiMotion/DS_input\",\n",
      "      \"autoMountLocal\": true,\n",
      "      \"targetPath\": \"inputDirectory\"\n",
      "    }\n",
      "  ],\n",
      "  \"parameterSet\": {\n",
      "    \"appArgs\": [\n",
      "      {\n",
      "        \"name\": \"Main Script\",\n",
      "        \"arg\": \"Main_multiMotion.tcl\"\n",
      "      }\n",
      "    ],\n",
      "    \"schedulerOptions\": [\n",
      "      {\n",
      "        \"name\": \"TACC Allocation\",\n",
      "        \"arg\": \"-A ASC25049\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "------------------------------------\n",
      "Job submitted successfully. UUID: 24938b27-854f-4a75-a687-fe21e8723b36-007\n",
      "Job launched with UUID: 24938b27-854f-4a75-a687-fe21e8723b36-007\n",
      "Can also check in DesignSafe portal under - Workspace > Tools & Application > Job Status\n"
     ]
    }
   ],
   "source": [
    "# Submit job using dapi\n",
    "submitted_job = ds.jobs.submit_request(job_dict)\n",
    "print(f\"Job launched with UUID: {submitted_job.uuid}\")\n",
    "print(\n",
    "    \"Can also check in DesignSafe portal under - Workspace > Tools & Application > Job Status\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Monitoring Job: 24938b27-854f-4a75-a687-fe21e8723b36-007\n",
      "Job already in terminal state: FINISHED\n",
      "Job finished with status: FINISHED\n",
      "Job 24938b27-854f-4a75-a687-fe21e8723b36-007 completed successfully.\n",
      "\n",
      "Runtime Summary\n",
      "---------------\n",
      "QUEUED  time: 00:03:57\n",
      "RUNNING time: 00:01:01\n",
      "TOTAL   time: 00:06:59\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# Monitor job status using dapi\n",
    "final_status = submitted_job.monitor(interval=15)\n",
    "print(f\"Job finished with status: {final_status}\")\n",
    "\n",
    "# Interpret job status\n",
    "ds.jobs.interpret_status(final_status, submitted_job.uuid)\n",
    "\n",
    "# Display runtime summary\n",
    "submitted_job.print_runtime_summary(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "# Postprocess Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### Identify job and archived location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive URI: tapis://stampede3/work2/05873/kks32/stampede3/tapis-jobs-archive/2025-06-05Z/opensees-MP-multiMotion-dapi-24938b27-854f-4a75-a687-fe21e8723b36-007\n",
      "Listing files in system 'stampede3' at path 'work2/05873/kks32/stampede3/tapis-jobs-archive/2025-06-05Z/opensees-MP-multiMotion-dapi-24938b27-854f-4a75-a687-fe21e8723b36-007'...\n",
      "Found 6 items.\n",
      "\n",
      "Archive contents:\n",
      "- inputDirectory (dir)\n",
      "- opensees.zip (file)\n",
      "- tapisjob.env (file)\n",
      "- tapisjob.out (file)\n",
      "- tapisjob.sh (file)\n",
      "- tapisjob_app.sh (file)\n"
     ]
    }
   ],
   "source": [
    "# Get archive information using dapi\n",
    "archive_uri = submitted_job.archive_uri\n",
    "print(f\"Archive URI: {archive_uri}\")\n",
    "\n",
    "# List archive contents\n",
    "archive_files = ds.files.list(archive_uri)\n",
    "print(\"\\nArchive contents:\")\n",
    "for item in archive_files:\n",
    "    print(f\"- {item.name} ({item.type})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### Go to archived folder"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download archive files to local directory for postprocessing\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "# Create temporary directory for downloaded files\n",
    "temp_dir = tempfile.mkdtemp(prefix=\"opensees_results_\")\n",
    "print(f\"Downloading results to: {temp_dir}\")\n",
    "\n",
    "# Download the inputDirectory folder which contains results\n",
    "input_dir_archive_uri = f\"{archive_uri}/inputDirectory\"\n",
    "try:\n",
    "    # List contents of inputDirectory in archive\n",
    "    input_dir_files = ds.files.list(input_dir_archive_uri)\n",
    "    print(\"\\nFiles in inputDirectory:\")\n",
    "    for item in input_dir_files:\n",
    "        print(f\"- {item.name} ({item.type})\")\n",
    "\n",
    "    # Download all files from inputDirectory (excluding subdirectories)\n",
    "    files_to_download = [item.name for item in input_dir_files if item.type == \"file\"]\n",
    "\n",
    "    print(f\"\\nDownloading {len(files_to_download)} files...\")\n",
    "    successful_downloads = []\n",
    "\n",
    "    for filename in files_to_download:\n",
    "        try:\n",
    "            file_uri = f\"{input_dir_archive_uri}/{filename}\"\n",
    "            local_path = os.path.join(temp_dir, filename)\n",
    "\n",
    "            # Try downloading with the ds.files.download method\n",
    "            try:\n",
    "                ds.files.download(file_uri, local_path)\n",
    "                print(f\"Downloaded: {filename}\")\n",
    "                successful_downloads.append(filename)\n",
    "            except Exception as download_error:\n",
    "                print(f\"Standard download failed for {filename}: {download_error}\")\n",
    "\n",
    "                # Try alternative download approach using get_file_content\n",
    "                try:\n",
    "                    content = ds.files.get_file_content(file_uri)\n",
    "                    with open(local_path, \"wb\") as f:\n",
    "                        if hasattr(content, \"read\"):\n",
    "                            shutil.copyfileobj(content, f)\n",
    "                        else:\n",
    "                            f.write(content)\n",
    "                    print(f\"Downloaded (alternative method): {filename}\")\n",
    "                    successful_downloads.append(filename)\n",
    "                except Exception as alt_error:\n",
    "                    print(\n",
    "                        f\"Alternative download also failed for {filename}: {alt_error}\"\n",
    "                    )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Could not download {filename}: {e}\")\n",
    "\n",
    "    print(\n",
    "        f\"\\nSuccessfully downloaded {len(successful_downloads)} out of {len(files_to_download)} files\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing archive: {e}\")\n",
    "\n",
    "# Change to the temporary directory for postprocessing\n",
    "os.chdir(temp_dir)\n",
    "print(f\"\\nChanged to directory: {os.getcwd()}\")\n",
    "print(\"Local files:\")\n",
    "for f in sorted(os.listdir(\".\")):\n",
    "    print(f\"- {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "### Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7e7421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/krishna/dev/designsafe/dapi/env/lib/python3.11/site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/krishna/dev/designsafe/dapi/env/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/krishna/dev/designsafe/dapi/env/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/krishna/dev/designsafe/dapi/env/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp311-cp311-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached contourpy-1.3.2-cp311-cp311-macosx_11_0_arm64.whl (254 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.1-cp311-cp311-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.8-cp311-cp311-macosx_11_0_arm64.whl (65 kB)\n",
      "Using cached pillow-11.2.1-cp311-cp311-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.1 kiwisolver-1.4.8 matplotlib-3.10.3 pillow-11.2.1 pyparsing-3.2.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install matplotlib  # Install matplotlib for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### Plot acceleration response spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "Plot acceleration response spectra on log-linear scale"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define response spectra function inline\n",
    "def resp_spectra(a, time, nstep):\n",
    "    \"\"\"\n",
    "    This function builds response spectra from acceleration time history,\n",
    "    a should be a numpy array,T and nStep should be integers.\n",
    "    \"\"\"\n",
    "    # add initial zero value to acceleration and change units\n",
    "    a = np.insert(a, 0, 0)\n",
    "    # number of periods at which spectral values are to be computed\n",
    "    nperiod = 100\n",
    "    # define range of considered periods by power of 10\n",
    "    minpower = -3.0\n",
    "    maxpower = 1.0\n",
    "    # create vector of considered periods\n",
    "    p = np.logspace(minpower, maxpower, nperiod)\n",
    "    # incremental circular frequency\n",
    "    dw = 2.0 * np.pi / time\n",
    "    # vector of circular freq\n",
    "    w = np.arange(0, (nstep + 1) * dw, dw)\n",
    "    # fast fourier transform of acceleration\n",
    "    afft = np.fft.fft(a)\n",
    "    # arbitrary stiffness value\n",
    "    k = 1000.0\n",
    "    # damping ratio\n",
    "    damp = 0.05\n",
    "    umax = np.zeros(nperiod)\n",
    "    vmax = np.zeros(nperiod)\n",
    "    amax = np.zeros(nperiod)\n",
    "    # loop to compute spectral values at each period\n",
    "    for j in range(0, nperiod):\n",
    "        # compute mass and dashpot coeff to produce desired periods\n",
    "        m = ((p[j] / (2 * np.pi)) ** 2) * k\n",
    "        c = 2 * damp * (k * m) ** 0.5\n",
    "        h = np.zeros(nstep + 2, dtype=complex)\n",
    "        # compute transfer function\n",
    "        for l in range(0, int(nstep / 2 + 1)):\n",
    "            h[l] = 1.0 / (-m * w[l] * w[l] + 1j * c * w[l] + k)\n",
    "            # mirror image of transfer function\n",
    "            h[nstep + 1 - l] = np.conj(h[l])\n",
    "\n",
    "        # compute displacement in frequency domain using transfer function\n",
    "        qfft = -m * afft\n",
    "        u = np.zeros(nstep + 1, dtype=complex)\n",
    "        for l in range(0, nstep + 1):\n",
    "            u[l] = h[l] * qfft[l]\n",
    "\n",
    "        # compute displacement in time domain (ignore imaginary part)\n",
    "        utime = np.real(np.fft.ifft(u))\n",
    "\n",
    "        # spectral displacement, velocity, and acceleration\n",
    "        umax[j] = np.max(np.abs(utime))\n",
    "        vmax[j] = (2 * np.pi / p[j]) * umax[j]\n",
    "        amax[j] = (2 * np.pi / p[j]) * vmax[j]\n",
    "\n",
    "    return p, umax, vmax, amax\n",
    "\n",
    "\n",
    "# Define plot_acc function inline\n",
    "def plot_acc():\n",
    "    \"\"\"\n",
    "    Plot acceleration time history and response spectra\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Check for available acceleration files\n",
    "    acc_files = []\n",
    "    for motion in [\"motion1\", \"motion2\"]:\n",
    "        for profile in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            filename = f\"Profile{profile}_acc{motion}.out\"\n",
    "            if os.path.exists(filename):\n",
    "                acc_files.append((motion, profile, filename))\n",
    "\n",
    "    if not acc_files:\n",
    "        print(\"No acceleration output files found.\")\n",
    "        print(\"Available files in current directory:\")\n",
    "        for f in os.listdir(\".\"):\n",
    "            if f.endswith(\".out\"):\n",
    "                print(f\"- {f}\")\n",
    "        return\n",
    "\n",
    "    # Create subplot for response spectra\n",
    "    plt.subplot(2, 1, 1)\n",
    "\n",
    "    colors = [\"b\", \"r\", \"g\", \"m\"]\n",
    "    motion_styles = {\"motion1\": \"-\", \"motion2\": \"--\"}\n",
    "\n",
    "    for i, (motion, profile, filename) in enumerate(acc_files):\n",
    "        try:\n",
    "            acc = np.loadtxt(filename)\n",
    "            if acc.size > 0 and acc.ndim >= 2:\n",
    "                [p, umax, vmax, amax] = resp_spectra(\n",
    "                    acc[:, -1], acc[-1, 0], acc.shape[0]\n",
    "                )\n",
    "                color = colors[ord(profile) - ord(\"A\")]\n",
    "                style = motion_styles[motion]\n",
    "                plt.semilogx(\n",
    "                    p,\n",
    "                    amax,\n",
    "                    color=color,\n",
    "                    linestyle=style,\n",
    "                    label=f\"Profile {profile}, {motion}\",\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "    plt.ylabel(\"$S_a (g)$\")\n",
    "    plt.xlabel(\"$Period (s)$\")\n",
    "    plt.title(\"Acceleration Response Spectra\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subplot for time history (if data available)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    for i, (motion, profile, filename) in enumerate(\n",
    "        acc_files[:4]\n",
    "    ):  # Show first 4 files\n",
    "        try:\n",
    "            acc = np.loadtxt(filename)\n",
    "            if acc.size > 0 and acc.ndim >= 2:\n",
    "                time = np.linspace(0, acc[-1, 0], acc.shape[0])\n",
    "                color = colors[i % len(colors)]\n",
    "                plt.plot(\n",
    "                    time,\n",
    "                    acc[:, -1],\n",
    "                    color=color,\n",
    "                    alpha=0.7,\n",
    "                    label=f\"Profile {profile}, {motion}\",\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting time history for {filename}: {e}\")\n",
    "\n",
    "    plt.ylabel(\"Acceleration (g)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.title(\"Acceleration Time History\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Execute the plotting function\n",
    "plot_acc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}